# DRIFT DETECTION & CONTINUOUS MONITORING CONTROLS

**Confidential & Privileged**
**Control Function:** Production Health & Stability
**Monitoring Frequency:** Continuous (Real-Time) + Daily Batch

---

## 1. The Stability Mandate

In a regulated environment, an AI model that changes its behavior unpredictably is a safety hazard. We employ rigorous statistical monitoring to ensuring the "Frozen Core" remains valid relative to the changing world data.

**Core Principle:** *If the world changes too much, the Map (Model) is no longer valid.*

## 2. Key Drift Metrics Monitored

We monitor four distinct dimensions of model stability:

### 2.1 Input Data Drift (Feature Shift)
We track the statistical distribution of incoming data against the "Training Baseline".
*   **What it checks:** "Are we seeing customers or transaction types that the model has never seen before?"
*   **Example:** A sudden spike in transactions from a previously quiet jurisdiction.
*   **Metric:** Population Stability Index (PSI).
    *   PSI < 0.1: Stable.
    *   PSI > 0.25: **CRITICAL DRIFT ALERT.**

### 2.2 Output Drift (prediction Shift)
We track the distribution of the Risk Scores generated by the system.
*   **What it checks:** "Is the model flagging significantly more (or fewer) people than usual today?"
*   **Example:** If the "High Risk" rate jumps from 2% to 15% overnight without a corresponding external event.
*   **Metric:** Kullback-Leibler (KL) Divergence.

### 2.3 Decision Aggressiveness Drift
We monitor the rate of severe classifications.
*   **Defensive Guardrail:** To prevent denial-of-service to legitimate customers.
*   **Metric:** Daily "Block Rate" variance. Any deviation > 15% from the rolling 30-day average triggers an operational alert.

### 2.4 Confidence Decay
We monitor the internal confidence score (probability) of the model's top predictions.
*   **What it checks:** "Is the model becoming 'unsure'?"
*   **Trigger:** If average confidence drops below 75%, it suggests the current market behavior is outside the model's "Knowledge Domain".

## 3. Alert Thresholds & Severity Levels

| Severity | Indicator | Threshold | Automated Action | Human Resolution |
| :--- | :--- | :--- | :--- | :--- |
| **P3: Warning** | Single Feature PSI | > 0.1 | Log Warning | Analyst reviews data quality (ETL check). |
| **P2: Critical** | Global PSI | > 0.25 | **Suspend Batch Processing** | Risk Officer must approve "Emergency Bypass" or confirm data validity. |
| **P1: Fatal** | Accuracy/Recall | < 90% | **KILL SWITCH** | Revert to Manual Review / Rules Engine immediately. |

## 4. The "No-Auto-Learn" Response Protocol

**CRITICAL REGULATORY CONTROL:**
When significant drift is detected, the system is **strictly prohibited** from automatically adjusting/retraining itself to compensate.

### The Drift Response Workflow:
1.  **Alert Generation:** Dashboard lights up red; email sent to CRO and Lead Data Scientist.
2.  **Circuit Breaker (Optional):** If P1 severity, the AI inference is paused.
3.  **Root Cause Analysis:** Human team investigates. Is this a data feed error? Or a genuine change in fraud patterns?
4.  **Remediation Decision:**
    *   *Scenario A (Data Error):* Fix the ETL pipeline. Resume AI.
    *   *Scenario B (True Market Shift):* The Model is declared "Stale".
5.  **Offline Retraining:** A **NEW** model version is trained in the sandbox, validated, and manually deployed via the formal Change Management process.

**Summary:** The system detects drift automatically, but fixes it manually.

---
**Monitoring Configuration Approved By:**
*Head of Data Governance*
