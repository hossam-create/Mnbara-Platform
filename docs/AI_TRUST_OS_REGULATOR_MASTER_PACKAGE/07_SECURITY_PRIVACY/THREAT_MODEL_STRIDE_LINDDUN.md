# Threat Model: AI Trust & Risk Operating System (STRIDE + LINDDUN)

**Document ID:** SEC-TM-AI-001
**Methodology:** STRIDE (Security) + LINDDUN (Privacy)
**Audience:** Security Architects, GRC Officers, External Auditors
**Status:** VALIDATED FOR PRODUCTION

---

## 1. System Scope & Assets

**1.1 Critical Assets:**
*   **Rule Logic (IP):** The proprietary definition of risk policies.
*   **Transaction Context (PII/Financial):** Ephemeral input data used for scoring.
*   **Audit Logs (Evidence):** Immutable record of decisions for regulatory defense.
*   **Human Override Decisions:** Labels generated by human operators (valuable for tuning).

**1.2 Trust Boundaries:**
*   **Boundary A (Public/Private):** API Gateway accepting incoming requests (Untrusted -> Trusted).
*   **Boundary B (Logic/Data):** Context Assembler fetching PII from internal stores (Trusted -> Trusted high-sensitivity).
*   **Boundary C (Execution):** Read-Only barrier preventing Risk Engine from writing to Core Ledger.

**1.3 Out of Scope:**
*   **Identity Provisioning:** Handled by external IdP (Auth0/Okta).
*   **Payment Execution:** Handled by Payment PSP (Stripe/Adyen).

---

## 2. Threat Modeling Methodology

We utilize a hybrid approach:
1.  **STRIDE:** Validates the technical security of the application components against standard attack vectors.
2.  **LINDDUN:** Specifically assesses the privacy impact of data processing, critical for GDPR compliance in decisioning systems.
3.  **Deterministic Assumption:** All threat scnearios assume the code executes exactly as written (no "hallucinations"), shifting focus to **logic manipulation** and **data integrity**.

---

## 3. STRIDE Analysis (Security)

| Category | Threat Description | Likelihood | Impact | Mitigation | Residual Risk |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Spoofing** | Attacker impersonates the "Payment Gateway" to send fake transaction checks. | Low | Medium | mTLS authentication between microservices; API Key validation. | Low |
| **Tampering** | Rogue employee modifies a Rule Set to bypass fraud checks for specific users. | Medium | Critical | Rules managed as Code (Git); Multi-party approval required for merge; Signed artifacts. | Low |
| **Repudiation** | Admin denies deleting a critical audit log after an incident. | Low | High | **WORM Storage** (Write-Once-Read-Many) for logs; System Admins possess NO delete permissions. | Low |
| **Info Disclosure** | Support agent views "Logic Trace" and leaks fraud rules to bad actors. | High | Medium | RBAC limits trace visibility; Trace output is sanitized (generic reason codes vs detailed logic). | Medium |
| **DoS** | Attacker floods the decision API to halt business processing. | High | High | Stateless Auto-scaling; "Fail-Safe" Circuit Breakers (default to queue, don't crash). | Low |
| **Elevation** | A "Read-Only" analyst promotes themselves to "Rule Approver". | Low | High | Identity Provider (IdP) groups strictly synced; Role changes require Executive sign-off. | Low |

---

## 4. LINDDUN Analysis (Privacy)

| Category | Privacy Threat | Mitigation Control | Compliance impact |
| :--- | :--- | :--- | :--- |
| **Linkability** | Linking a sanitized "User ID" in logs back to a real person. | **Pseudonymization:** IDs are hashed before logging. Re-identification requires separate key held by Compliance. | GDPR Art. 32 |
| **Identifiability** | Inferring identity from "Device Fingerprint" + "IP". | **Ephemeral Processing:** Raw device signals processed in RAM only, then discarded. Only the "Risk Signal" is stored. | Data Minimization |
| **Non-Repudiation** | User cannot deny a transaction because logs are too detailed. | **feature:** This is a *feature* for Non-Repudiation of fraud, legally protected under "Legitimate Interest" (Fraud Prevention). | AML Regulations |
| **Detectability**| Attacker detects a user is "High Risk" by timing API response latency. | **Constant-Time Execution:** Rule engine executes in bounded time regardless of branch taken to prevent timing attacks. | Operational Sec |
| **Disclosure** | Leaking sensitive PII (Salary, Address) to the Risk Engine. | **Schema Validation:** System explicitly drops any field not defined in the "Allowed Input Schema" before processing. | Confidentiality |
| **Unawareness** | User doesn't know they are being scored. | **Terms of Service:** Explicit disclosure of "Fraud Monitoring" in user agreement; Public Trust Statement. | Transparency |
| **Non-Compliance**| Analyzing data across borders (EU data in US server). | **Regional Isolation:** Rule Engines deployed per region; Data does not cross sovereign borders for processing. | Cross-Border Data |

---

## 5. AI-Specific Threats & Controls (The "Governor" Layer)

**5.1 Threat: Model Gaming / Evasion**
*   *Scenario:* Fraudsters probe the system to find the exact "Velocity Limit" (e.g., 5 tx/hour).
*   *Control:* **Fuzzy Reason Codes**. The system returns specific codes to the *internal* team, but generic "Security Alert" messages to the *user/API* to prevent reverse-engineering.

**5.2 Threat: Feedback Poisoning**
*   *Scenario:* A compromised human operator repeatedly approves fraud to "teach" the system it's safe (if ML were used).
*   *Control:* **No Online Learning**. Since the system is deterministic, human overrides *do not* automatically update the logic. They are only log entries. Poisoning is technically impossible.

**5.3 Threat: Shadow Evaluation Abuse**
*   *Scenario:* Deploying a "Shadow Rule" that siphons data to an unauthorized endpoint.
*   *Control:* **Egress Filtering.** The Shadow Environment has strictly no outbound network access (internet disabled). It can only write to the internal log stream.

---

## 6. Threat Summary Matrix

| Threat ID | Threat | Method | Severity | Control Type | Status |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **S-01** | Rule Logic Tampering | STRIDE | **Critical** | Governance (GitOps) | Mitigated |
| **S-02** | Audit Log Deletion | STRIDE | **Critical** | Technical (WORM) | Mitigated |
| **L-01** | PII Leakage in Logs | LINDDUN | **High** | Tech (Hashing) | Mitigated |
| **L-02** | EU/US Data Cross | LINDDUN | **Medium** | Architecture (Geo) | Mitigated |
| **AI-01** | Model Reverse Eng | AI Specific | **Medium** | Obfuscation | Managed |

---

## 7. Security & Privacy Posture Statement

**Security Posture:**
The AI Trust & Risk Operating System presents a **Low Residual Risk** profile due to its architectural constraints. By enforcing **Determinism** and **Read-Only** access, we eliminate the two largest vectors for AI risk: "Runaway Autonomous Action" and "Data Corruption."

**Privacy Posture:**
The system is built on **Privacy by Design** principles. It processes personal data solely for the legal basis of **Fraud Prevention (Legitimate Interest)** and **Regulatory Compliance (Legal Obligation)**. Implementing **Data Minimization** at the schema level ensures that "excessive" data is technically rejected at the door.

**Auditor Conclusion:**
This controls framework is sufficient for **SOC 2 Type II** observation and meets the stringent requirements of ISO 27001 Annex A for secure system engineering.

---
**Approved By:**
Chief Information Security Officer (CISO)
Data Protection Officer (DPO)
